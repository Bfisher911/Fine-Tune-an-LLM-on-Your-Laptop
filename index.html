<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Infographic: Fine-Tuning a Small LLM on Your Laptop</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #F8FAFC;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 500px;
            margin-left: auto;
            margin-right: auto;
            height: 320px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 400px;
            }
        }
        .flow-line {
            position: relative;
            flex-grow: 1;
            background-color: #94D2BD;
            height: 4px;
            margin: 0 1rem;
        }
        .flow-line::after {
            content: '';
            position: absolute;
            right: -8px;
            top: -6px;
            border-top: 8px solid transparent;
            border-bottom: 8px solid transparent;
            border-left: 8px solid #94D2BD;
        }
        .flow-branch-down {
            position: relative;
            width: 4px;
            background-color: #94D2BD;
            margin: 0 auto;
        }
        .flow-branch-down.h-16 { height: 4rem; }
        .flow-branch-down::after {
            content: '';
            position: absolute;
            bottom: -8px;
            left: -6px;
            border-left: 8px solid transparent;
            border-right: 8px solid transparent;
            border-top: 8px solid #94D2BD;
        }
    </style>
</head>
<body class="text-gray-800">

    <div class="container mx-auto p-4 md:p-8 max-w-7xl">

        <header class="text-center py-12">
            <h1 class="text-4xl md:text-6xl font-black text-[#005F73] tracking-tight">Fine-Tune an LLM on Your Laptop</h1>
            <p class="mt-4 text-lg md:text-xl text-[#0A9396] max-w-3xl mx-auto">A visual guide to the concepts and steps for training a small language model using LoRA, QLoRA, or the Gemini CLI.</p>
        </header>

        <main class="space-y-16">
            
            <section id="setup" class="bg-white rounded-2xl shadow-lg p-6 md:p-10">
                <h2 class="text-3xl font-bold text-center text-[#005F73] mb-8">1. Are You Ready? Hardware & Software Check</h2>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-8 text-center">
                    <div class="bg-slate-50 rounded-xl p-6">
                        <p class="text-6xl font-extrabold text-[#EE9B00]">8<span class="text-4xl">GB+</span></p>
                        <p class="mt-2 text-lg font-semibold text-[#005F73]">System RAM</p>
                        <p class="text-sm text-gray-600">The minimum required to hold the model weights in memory.</p>
                    </div>
                    <div class="bg-slate-50 rounded-xl p-6">
                        <p class="text-6xl font-extrabold text-[#CA6702]">‚úì</p>
                         <p class="mt-2 text-lg font-semibold text-[#005F73]">No GPU Needed</p>
                         <p class="text-sm text-gray-600">A dedicated GPU (‚â•6GB VRAM) speeds things up, but your CPU will work just fine.</p>
                    </div>
                    <div class="bg-slate-50 rounded-xl p-6">
                        <p class="text-6xl font-extrabold text-[#AE2012]">3.10+</p>
                        <p class="mt-2 text-lg font-semibold text-[#005F73]">Python Version</p>
                        <p class="text-sm text-gray-600">All the required libraries are tested and compatible with these versions.</p>
                    </div>
                </div>
            </section>

            <section id="comparison" class="bg-white rounded-2xl shadow-lg p-6 md:p-10">
                <h2 class="text-3xl font-bold text-center text-[#005F73] mb-8">2. The Big Picture: LoRA vs. QLoRA</h2>
                <p class="text-center max-w-3xl mx-auto text-gray-700 mb-10">Both techniques fine-tune a model by adding tiny, trainable "adapter" layers, leaving the massive original model weights frozen. This dramatically reduces memory needs. QLoRA goes a step further by quantizing the frozen weights to 4-bit, saving even more memory.</p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8 items-center">
                    <div>
                        <h3 class="text-xl font-bold text-center text-[#0A9396] mb-4">Memory Footprint Comparison</h3>
                        <div class="chart-container h-64 md:h-80">
                            <canvas id="loraComparisonChart"></canvas>
                        </div>
                         <p class="text-sm text-center text-gray-600 mt-4">QLoRA's 4-bit quantization more than halves the memory footprint compared to standard LoRA, making it ideal for hardware with less than 12GB of RAM.</p>
                    </div>
                    <div class="bg-slate-50 rounded-xl p-6 text-center">
                        <h3 class="text-xl font-bold text-[#0A9396] mb-4">When to Pick Which?</h3>
                        <div class="space-y-4">
                            <div class="p-4 bg-blue-100/50 border-l-4 border-[#0A9396] rounded-r-lg">
                                <p class="font-bold text-[#005F73]">Choose LoRA if...</p>
                                <p class="text-gray-700 text-sm">You have ‚â• 12GB of system RAM or a decent GPU. It's slightly faster due to higher-precision math.</p>
                            </div>
                            <div class="p-4 bg-orange-100/50 border-l-4 border-[#EE9B00] rounded-r-lg">
                                <p class="font-bold text-[#CA6702]">Choose QLoRA if...</p>
                                <p class="text-gray-700 text-sm">You need to squeeze into less than 8GB of RAM. The trade-off is slightly slower training speed.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            
            <section id="flowchart" class="bg-white rounded-2xl shadow-lg p-6 md:p-10">
                <h2 class="text-3xl font-bold text-center text-[#005F73] mb-2">3. Choose Your Adventure</h2>
                <p class="text-center max-w-3xl mx-auto text-gray-700 mb-12">The lab offers three paths to a fine-tuned model. The first two use Python scripts you run directly, while the third offloads the work to Google Cloud.</p>
                <div class="flex flex-col items-center">
                    <div class="bg-[#005F73] text-white py-3 px-6 rounded-full shadow-md">Start: Prep & Pick Model/Data</div>
                    <div class="flow-branch-down h-16"></div>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-x-8 gap-y-12 w-full text-center relative">
                        <div class="absolute top-[-3rem] left-0 right-0 h-1 bg-[#94D2BD] hidden md:block w-3/4 mx-auto"></div>
                        <div class="absolute top-[-3rem] left-1/2 md:left-1/4 -translate-x-1/2 w-1 h-8 bg-[#94D2BD] hidden md:block"></div>
                        <div class="absolute top-[-3rem] left-1/2 -translate-x-1/2 w-1 h-8 bg-[#94D2BD] hidden md:block"></div>
                        <div class="absolute top-[-3rem] right-1/4 left-auto -translate-x-1/2 w-1 h-8 bg-[#94D2BD] hidden md:block"></div>

                        <div class="flex flex-col items-center">
                             <h4 class="text-lg font-bold text-[#0A9396] mb-4 border-2 border-[#94D2BD] rounded-lg py-2 px-4">Option A: LoRA</h4>
                             <p class="text-sm text-gray-600 h-16">Classic method, best for systems with more RAM.</p>
                             <div class="flow-branch-down h-16"></div>
                             <div class="bg-slate-100 p-4 rounded-lg w-full shadow">Attach `LoraConfig`</div>
                             <div class="flow-branch-down h-16"></div>
                             <div class="bg-slate-100 p-4 rounded-lg w-full shadow">Run `Trainer.train()`</div>
                        </div>
                        
                        <div class="flex flex-col items-center">
                            <h4 class="text-lg font-bold text-[#EE9B00] mb-4 border-2 border-[#E9D8A6] rounded-lg py-2 px-4">Option B: QLoRA</h4>
                            <p class="text-sm text-gray-600 h-16">4-bit version for max memory savings on any machine.</p>
                             <div class="flow-branch-down h-16"></div>
                            <div class="bg-orange-50 p-4 rounded-lg w-full shadow">Load model with `BitsAndBytesConfig`</div>
                             <div class="flow-branch-down h-16"></div>
                             <div class="bg-orange-50 p-4 rounded-lg w-full shadow">Run `Trainer.train()`</div>
                        </div>

                        <div class="flex flex-col items-center">
                             <h4 class="text-lg font-bold text-[#AE2012] mb-4 border-2 border-[#f5b0ac] rounded-lg py-2 px-4">Option C: Gemini CLI</h4>
                              <p class="text-sm text-gray-600 h-16">Scaffold code and run locally or on Google's Vertex AI.</p>
                             <div class="flow-branch-down h-16"></div>
                            <div class="bg-red-50 p-4 rounded-lg w-full shadow">Run `gemini models adapt`</div>
                             <div class="flow-branch-down h-16"></div>
                            <div class="bg-red-50 p-4 rounded-lg w-full shadow">Run locally or deploy to Vertex AI</div>
                        </div>
                    </div>
                </div>
            </section>
            
            <section id="tools" class="bg-white rounded-2xl shadow-lg p-6 md:p-10">
                <h2 class="text-3xl font-bold text-center text-[#005F73] mb-8">4. Pick Your Tools: Models & Datasets</h2>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-12 items-center">
                    <div>
                        <h3 class="text-xl font-bold text-center text-[#0A9396] mb-4">Base Model Comparison</h3>
                        <div class="chart-container">
                            <canvas id="modelComparisonChart"></canvas>
                        </div>
                         <p class="text-sm text-center text-gray-600 mt-4">The lab defaults to Phi-3-mini, a great balance of size and capability. Larger models are more powerful but require more resources.</p>
                    </div>
                    <div>
                        <h3 class="text-xl font-bold text-center text-[#0A9396] mb-6">Choose a Micro-Dataset</h3>
                        <div class="space-y-4">
                            <div class="flex items-start space-x-4 p-4 bg-slate-50 rounded-lg">
                                <span class="text-3xl">üì∞</span>
                                <div>
                                    <h4 class="font-bold text-[#005F73]">News Summaries</h4>
                                    <p class="text-sm text-gray-600">Train the model to shrink long science abstracts into two sentences.</p>
                                </div>
                            </div>
                            <div class="flex items-start space-x-4 p-4 bg-slate-50 rounded-lg">
                                <span class="text-3xl">üí¨</span>
                                <div>
                                    <h4 class="font-bold text-[#005F73]">Help-Desk Chat</h4>
                                    <p class="text-sm text-gray-600">Train the model to answer IT support questions in plain English.</p>
                                </div>
                            </div>
                            <div class="flex items-start space-x-4 p-4 bg-slate-50 rounded-lg">
                                <span class="text-3xl">üé¨</span>
                                <div>
                                    <h4 class="font-bold text-[#005F73]">Movie Sentiment</h4>
                                    <p class="text-sm text-gray-600">Train the model to classify a review as "Positive" or "Negative".</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

             <section id="payoff" class="bg-white rounded-2xl shadow-lg p-6 md:p-10">
                <h2 class="text-3xl font-bold text-center text-[#005F73] mb-8">5. The Payoff: Evaluation & Results</h2>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8 items-center">
                    <div class="text-center">
                        <h3 class="text-xl font-bold text-[#0A9396] mb-4">Trainable vs. Frozen Parameters</h3>
                        <div class="chart-container h-64 md:h-80">
                            <canvas id="trainableParamsChart"></canvas>
                        </div>
                        <p class="text-sm text-center text-gray-600 mt-4">LoRA/QLoRA methods are efficient because they only train a tiny fraction of the total parameters (often less than 1%), keeping the vast majority of the model frozen.</p>
                    </div>
                     <div class="bg-slate-50 rounded-xl p-8 text-center">
                        <h3 class="text-xl font-bold text-[#0A9396] mb-4">What is Perplexity?</h3>
                        <p class="text-6xl font-extrabold text-[#EE9B00]">‚¨áÔ∏è</p>
                        <p class="mt-2 text-2xl font-semibold text-[#005F73]">Lower is Better</p>
                        <p class="text-gray-700 mt-4">Perplexity measures how "surprised" a model is by new text. After fine-tuning on a specific task (like IT help), the model should be less surprised by text from that domain, resulting in a **lower perplexity score** compared to the base model.</p>
                    </div>
                </div>
            </section>

        </main>

        <footer class="text-center py-10 mt-16 border-t border-gray-200">
            <p class="text-gray-600">This infographic visualizes the key concepts from the "Fine-Tuning a Small Language Model on Your Own Laptop" workshop guide.</p>
            <p class="text-sm text-gray-400 mt-2">Generated on July 5, 2025.</p>
        </footer>

    </div>

<script>
    const chartTooltipTitleCallback = (tooltipItems) => {
        const item = tooltipItems[0];
        let label = item.chart.data.labels[item.dataIndex];
        if (Array.isArray(label)) {
            return label.join(' ');
        }
        return label;
    };

    const wrapLabel = (label, maxWidth = 16) => {
        if (label.length <= maxWidth) return label;
        const words = label.split(' ');
        const lines = [];
        let currentLine = '';
        for (const word of words) {
            if ((currentLine + ' ' + word).trim().length > maxWidth && currentLine.length > 0) {
                lines.push(currentLine);
                currentLine = word;
            } else {
                currentLine = (currentLine + ' ' + word).trim();
            }
        }
        if (currentLine.length > 0) lines.push(currentLine);
        return lines;
    };
    
    const brilliantBlues = {
        primary: '#0A9396',
        secondary: '#94D2BD',
        accent1: '#EE9B00',
        accent2: '#CA6702',
        accent3: '#AE2012',
        text: '#005F73',
        grid: '#E0E0E0'
    };

    const loraComparisonCtx = document.getElementById('loraComparisonChart').getContext('2d');
    new Chart(loraComparisonCtx, {
        type: 'bar',
        data: {
            labels: ['LoRA', 'QLoRA'],
            datasets: [{
                label: 'Memory Footprint (% of Original Model)',
                data: [33, 15],
                backgroundColor: [brilliantBlues.primary, brilliantBlues.accent1],
                borderColor: [brilliantBlues.primary, brilliantBlues.accent1],
                borderWidth: 1
            }]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            scales: {
                y: {
                    beginAtZero: true,
                    title: { display: true, text: '% of Original Model Memory', color: brilliantBlues.text },
                    grid: { color: brilliantBlues.grid }
                },
                x: {
                   grid: { display: false }
                }
            },
            plugins: {
                legend: { display: false },
                tooltip: { callbacks: { title: chartTooltipTitleCallback } }
            }
        }
    });

    const modelComparisonCtx = document.getElementById('modelComparisonChart').getContext('2d');
    new Chart(modelComparisonCtx, {
        type: 'radar',
        data: {
            labels: ['Parameters (Billions)', 'Disk Size (GB)'],
            datasets: [
                {
                    label: 'TinyLlama-Chat',
                    data: [1.1, 0.5],
                    backgroundColor: 'rgba(10, 147, 150, 0.2)',
                    borderColor: 'rgba(10, 147, 150, 1)',
                    pointBackgroundColor: 'rgba(10, 147, 150, 1)',
                },
                {
                    label: 'Phi-3-mini (default)',
                    data: [3.8, 1.6],
                    backgroundColor: 'rgba(238, 155, 0, 0.2)',
                    borderColor: 'rgba(238, 155, 0, 1)',
                    pointBackgroundColor: 'rgba(238, 155, 0, 1)',
                },
                {
                    label: 'Mistral-7B-Instruct',
                    data: [7.0, 4.2],
                    backgroundColor: 'rgba(174, 32, 18, 0.2)',
                    borderColor: 'rgba(174, 32, 18, 1)',
                    pointBackgroundColor: 'rgba(174, 32, 18, 1)',
                }
            ]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            scales: {
                r: {
                    angleLines: { color: brilliantBlues.grid },
                    grid: { color: brilliantBlues.grid },
                    pointLabels: { font: { size: 14 }, color: brilliantBlues.text },
                    ticks: { backdropColor: '#F8FAFC', color: brilliantBlues.text }
                }
            },
            plugins: {
                legend: { position: 'top', labels: { color: brilliantBlues.text } },
                tooltip: { callbacks: { title: chartTooltipTitleCallback } }
            }
        }
    });

    const trainableParamsCtx = document.getElementById('trainableParamsChart').getContext('2d');
    new Chart(trainableParamsCtx, {
        type: 'doughnut',
        data: {
            labels: ['Frozen Parameters', 'Trainable Adapters'],
            datasets: [{
                label: 'Parameter Distribution',
                data: [99.2, 0.8],
                backgroundColor: [brilliantBlues.secondary, brilliantBlues.accent2],
                borderColor: ['#FFFFFF'],
                borderWidth: 2,
                hoverOffset: 4
            }]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            plugins: {
                legend: { position: 'bottom', labels: { color: brilliantBlues.text } },
                tooltip: { callbacks: { title: chartTooltipTitleCallback } }
            },
            cutout: '70%'
        }
    });

</script>
</body>
</html>
